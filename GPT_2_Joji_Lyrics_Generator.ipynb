{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "GPT-2 Joji Lyrics Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2vz8GC4hv14jJdWMAVaES",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meloly4/NLP-Projects/blob/master/GPT_2_Joji_Lyrics_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mPQvl8Gxnuv"
      },
      "source": [
        "GENIUS_API_TOKEN='rT5RsoMPpem87a-w4QyqBY1-Bw37wsJaPItxns05NXH8FcYSSVkqlO5PJyur9yC-'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I4foRzKyffd"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpd1t7ayyvEc"
      },
      "source": [
        "# Get artist info using Genius API\n",
        "def request_artist_info(artist_name, page):\n",
        "    base_url = 'https://api.genius.com'\n",
        "    headers = {'Authorization': 'Bearer ' + GENIUS_API_TOKEN}\n",
        "    search_url = base_url + '/search?per_page=10&page=' + str(page)\n",
        "    data = {'q': artist_name}\n",
        "    response = requests.get(search_url, data=data, headers=headers)\n",
        "    return response\n",
        "\n",
        "# Get song url\n",
        "def request_song_url(artist_name, song_cap):\n",
        "    page = 1\n",
        "    songs = []\n",
        "    \n",
        "    while True:\n",
        "        response = request_artist_info(artist_name, page)\n",
        "        json = response.json()\n",
        "        song_info = []\n",
        "        for hit in json['response']['hits']:\n",
        "            if artist_name.lower() in hit['result']['primary_artist']['name'].lower():\n",
        "                song_info.append(hit)\n",
        "        for song in song_info:\n",
        "            if (len(songs) < song_cap):\n",
        "                url = song['result']['url']\n",
        "                songs.append(url)\n",
        "            \n",
        "        if (len(songs) == song_cap):\n",
        "            break\n",
        "        else:\n",
        "            page += 1\n",
        "        \n",
        "    print('Found {} songs by {}'.format(len(songs), artist_name))\n",
        "    return songs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti--VgJN1g0F",
        "outputId": "a9eccd76-ca87-496a-ee92-034c57b4b86f"
      },
      "source": [
        "# Scrape lyrics from song url\n",
        "def scrape_song_lyrics(url):\n",
        "    page = requests.get(url)\n",
        "    html = BeautifulSoup(page.text, 'html.parser')\n",
        "    lyrics = html.find('div', class_='lyrics').get_text()\n",
        "    #remove identifiers and newline\n",
        "    lyrics = re.sub(r'[\\(\\[].*?[\\)\\]]', '', lyrics)\n",
        "    lyrics = os.linesep.join([s for s in lyrics.splitlines() if s])         \n",
        "    return lyrics\n",
        "\n",
        "def write_lyrics_to_file(artist_name, song_count):\n",
        "    f = open(artist_name.lower() + '.txt', 'wb')\n",
        "    urls = request_song_url(artist_name, song_count)\n",
        "    for url in urls:\n",
        "        lyrics = scrape_song_lyrics(url)\n",
        "        f.write(lyrics.encode(\"utf8\"))\n",
        "    f.close()\n",
        "    num_lines = sum(1 for line in open(artist_name.lower() + '.txt', 'rb'))\n",
        "    print('Wrote {} lines to file from {} songs'.format(num_lines, song_count))\n",
        "\n",
        "write_lyrics_to_file('Joji', 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 50 songs by Joji\n",
            "Wrote 1689 lines to file from 50 songs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_wcPMMsMRpd",
        "outputId": "8a5a63b6-8349-4251-b292-628743569b1b"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8wSlgXoDPCR",
        "outputId": "3bd57fc2-e1ea-4360-b9bf-7c85bae0862b"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 267Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 4.27Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 427Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:07, 70.5Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 482Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 5.95Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 6.14Mit/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzm0m1BtMhNB",
        "outputId": "4642005d-5652-4948-eecb-02638ab27796"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"joji.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "25cad188-9d05-4547-ac8c-a152c737a6d5"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=100,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              learning_rate=1e-5,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 16167 tokens\n",
            "Training...\n",
            "interrupted\n",
            "Saving checkpoint/run1/model-0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4RNY6RBI9LmL",
        "outputId": "5b21e7c1-94e3-432d-dfff-e26e21a43ca1"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In the last few days, evidence has emerged that the US government has engaged in systematic surveillance of the internet. It appears that this is a priority for the NSA and other intelligence agencies.\n",
            "\n",
            "As we have seen after the Edward Snowden leaks, the US government is collecting massive amounts of data on millions of people every day. It has amassed huge amounts of data on almost every type of digital phone call, email, social media, and instant messaging. It is collecting everything from the location of your house to your phone. It has collected a lot more data on people you know than you would like.\n",
            "\n",
            "Which is why the NSA is making this information public and being able to spy on every single one of us.\n",
            "\n",
            "The NSA does not tell you what your online habits are. It is not telling you if you are a member of a classified social network or not. It is not telling you if you are in the US or not. It is telling you how much time you spend online. It is telling you the time you spend online every day. And it is telling you what your online habits are.\n",
            "\n",
            "I have not interacted with anyone who has had my emails, texts, and calls intercepted by the NSA. I have not had my emails, calls, or texts intercepted by other NSA agencies. I have not even spoken to any of the people who have had their accounts and other online activity through the NSA.\n",
            "\n",
            "The only thing I have seen in my online life is some of the information that is being harvested.\n",
            "\n",
            "And I have been listening to a lot of data. I have been able to see where people are. I have been watching and listening to things that are being used on the internet.\n",
            "\n",
            "The NSA is using this data to spy on the internet, to track the movements of millions of people every day. This is absolutely unprecedented.\n",
            "\n",
            "The government is using it to surveil people in the US to spy on them. The government is using this information to spy on the internet, to track the movements of millions of people every day.\n",
            "\n",
            "It is very, very disturbing. It is very alarming. And the fact that this is happening is very disturbing.\n",
            "\n",
            "The US government is collecting all this information on so many different people. It's not just about Facebook, it's about every single social media company, every single email account, every single website you visit. It's all being collected by the NSA and using it to go after and take down all of us who are using them.\n",
            "\n",
            "The NSA is using this information to spy on the internet, to track the movements of millions of people every day. It's very, very disturbing. It is very disturbing.\n",
            "\n",
            "It's very disturbing. It is very disturbing. It is very disturbing.\n",
            "\n",
            "And it is very disturbing. It is very disturbing. It is very disturbing.\n",
            "\n",
            "And now, I want to talk about the fact that the NSA is using this information to spy on the internet. And to collect information.\n",
            "\n",
            "The NSA's use of the internet to monitor the internet is being directed at the US government. The NSA is using this information to spy on the internet, to monitor the movements of millions of people every day.\n",
            "\n",
            "The information that they are collecting is being used not only to monitor people's online habits but also to monitor all of us.\n",
            "\n",
            "The NSA is using the information to spy on people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "The information is being used to monitor people's online habits.\n",
            "\n",
            "And now, the fact that they are using this information to spy on us is very disturbing.\n",
            "\n",
            "The fact that they are using this information to monitor us is very disturbing.\n",
            "\n",
            "The fact that they are using this information to monitor us is very disturbing.\n",
            "\n",
            "The fact that they are using this information to monitor us is very disturbing.\n",
            "\n",
            "The fact that they are using this information to monitor us is very disturbing.\n",
            "\n",
            "The fact that they are using this information to monitor us is very disturbing.\n",
            "\n",
            "The fact that they are using this information to monitor us is very disturbing.\n",
            "\n",
            "The fact that they are using this information to monitor us is very disturbing.\n",
            "\n",
            "The fact that they are using this information to monitor us is very disturbing.\n",
            "\n",
            "The fact that they are using this information\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}